{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Library and Generate train-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_relukan import ReLUKANLayer, ReLUKAN\n",
    "from torch_hrkan import HRKANLayer, HRKAN\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import autograd\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "\n",
    "from kan import KAN, LBFGS\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "alpha = 0.05\n",
    "dim = 2\n",
    "np_i = 30\n",
    "np_b = 30 \n",
    "ranges = [-1, 1]\n",
    "\n",
    "def batch_jacobian(func, x, create_graph=False):\n",
    "    def _func_sum(x):\n",
    "        return func(x).sum(dim=0)\n",
    "    return autograd.functional.jacobian(_func_sum, x, create_graph=create_graph).permute(1,0,2)\n",
    "\n",
    "# define solution\n",
    "sol_fun = lambda x: torch.sin(torch.pi*x[:,[0]])*torch.sin(torch.pi*x[:,[1]])\n",
    "source_fun = lambda x: -2*torch.pi**2 * torch.sin(torch.pi*x[:,[0]])*torch.sin(torch.pi*x[:,[1]])\n",
    "\n",
    "# interior\n",
    "sampling_mode = 'random'\n",
    "\n",
    "x_mesh = torch.linspace(ranges[0],ranges[1],steps=np_i)\n",
    "y_mesh = torch.linspace(ranges[0],ranges[1],steps=np_i)\n",
    "X, Y = torch.meshgrid(x_mesh, y_mesh, indexing=\"ij\")\n",
    "if sampling_mode == 'mesh':\n",
    "    #mesh\n",
    "    x_i = torch.stack([X.reshape(-1,), Y.reshape(-1,)]).permute(1,0)\n",
    "else:\n",
    "    #random\n",
    "    x_i = torch.rand((np_i**2,2))*2-1\n",
    "\n",
    "# boundary, 4 sides\n",
    "helper = lambda X, Y: torch.stack([X.reshape(-1,), Y.reshape(-1,)]).permute(1,0)\n",
    "xb1 = helper(X[0], Y[0])\n",
    "xb2 = helper(X[-1], Y[0])\n",
    "xb3 = helper(X[:,0], Y[:,0])\n",
    "xb4 = helper(X[:,0], Y[:,-1])\n",
    "x_b = torch.cat([xb1, xb2, xb3, xb4], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_mode_test = 'mesh'\n",
    "\n",
    "x_test_mesh = torch.linspace(ranges[0],ranges[1],steps=100)\n",
    "y_test_mesh = torch.linspace(ranges[0],ranges[1],steps=100)\n",
    "X_test, Y_test = torch.meshgrid(x_test_mesh, y_test_mesh, indexing=\"ij\")\n",
    "if sampling_mode == 'mesh':\n",
    "    #mesh\n",
    "    x_test_i = torch.stack([X_test.reshape(-1,), Y_test.reshape(-1,)]).permute(1,0)\n",
    "else:\n",
    "    #random\n",
    "    x_test_i = torch.rand((np_i**2,2))*2-1\n",
    "    \n",
    "xb1_test = helper(X_test[0], Y_test[0])\n",
    "xb2_test = helper(X_test[-1], Y_test[0])\n",
    "xb3_test = helper(X_test[:,0], Y_test[:,0])\n",
    "xb4_test = helper(X_test[:,0], Y_test[:,-1])\n",
    "x_test_b = torch.cat([xb1_test, xb2_test, xb3_test, xb4_test], dim=0)\n",
    "\n",
    "X_test_np = X_test.clone().detach().numpy()\n",
    "Y_test_np = Y_test.clone().detach().numpy()\n",
    "x_test = torch.stack([X_test.reshape(-1,), Y_test.reshape(-1,)]).permute(1,0)\n",
    "sol = sol_fun(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check if have GPU and move data there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    x_i = x_i.cuda()\n",
    "    x_b = x_b.cuda()\n",
    "    x_test = x_test.cuda()\n",
    "    x_test_i = x_test_i.cuda()\n",
    "    x_test_b = x_test_b.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define the function to train ReLUKAN and HRKAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    plt.ion()\n",
    "    losses = []\n",
    "    pde_losses = []\n",
    "    bc_losses = []\n",
    "    pde_losses_test = []\n",
    "    bc_losses_test = []\n",
    "    l2_losses_test = []\n",
    "    l2_losses_std_test= []\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for e in range(3000):\n",
    "        opt.zero_grad()\n",
    "\n",
    "        sol_D1_fun = lambda x: batch_jacobian(model, x, create_graph=True)[:,0,:]\n",
    "        sol_D2 = batch_jacobian(sol_D1_fun, x_i, create_graph=True)[:,:,:]\n",
    "        lap = torch.sum(torch.diagonal(sol_D2, dim1=1, dim2=2), dim=1, keepdim=True)\n",
    "        source = source_fun(x_i)\n",
    "        pde_loss = torch.mean((lap - source)**2)\n",
    "\n",
    "        bc_true = sol_fun(x_b)\n",
    "        bc_pred = model(x_b)\n",
    "        bc_loss = torch.mean((bc_pred-bc_true)**2)\n",
    "\n",
    "        loss = alpha * pde_loss + bc_loss\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            sol_D2_test = batch_jacobian(sol_D1_fun, x_test_i, create_graph=False)[:,:,:]\n",
    "            lap_test = torch.sum(torch.diagonal(sol_D2_test, dim1=1, dim2=2), dim=1, keepdim=True)\n",
    "            source_test = source_fun(x_test_i)\n",
    "            pde_loss_test = torch.mean((lap_test - source_test)**2)\n",
    "    \n",
    "            bc_true_test = sol_fun(x_test_b)\n",
    "            bc_pred_test = model(x_test_b)\n",
    "            bc_loss_test = torch.mean((bc_pred_test-bc_true_test)**2)\n",
    "    \n",
    "            l2_test = torch.mean((model(x_test).cpu() - sol)**2)\n",
    "            l2_test_std = torch.std((model(x_test).cpu() - sol)**2)\n",
    "    \n",
    "            pde_losses.append(pde_loss.cpu().detach().numpy())\n",
    "            bc_losses.append(bc_loss.cpu().detach().numpy())\n",
    "            pde_losses_test.append(pde_loss_test.cpu().detach().numpy())\n",
    "            bc_losses_test.append(bc_loss_test.cpu().detach().numpy())\n",
    "            l2_losses_test.append(l2_test.cpu().detach().numpy())\n",
    "            l2_losses_std_test.append(l2_test_std.cpu().detach().numpy())\n",
    "\n",
    "    elapsed = (time.time() - start)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(x_test).cpu().clone().detach().numpy().reshape(X_test_np.shape)\n",
    "    \n",
    "    return output, losses, pde_losses, bc_losses, pde_losses_test, bc_losses_test, l2_losses_test, l2_losses_std_test, elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define the function to train KAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kan(model):\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    plt.ion()\n",
    "    losses = []\n",
    "    pde_losses = []\n",
    "    bc_losses = []\n",
    "    pde_losses_test = []\n",
    "    bc_losses_test = []\n",
    "    l2_losses_test = []\n",
    "    l2_losses_std_test= []\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for e in range(3000):\n",
    "        \n",
    "        if e % 5 == 0 and e < 50:\n",
    "            model.update_grid_from_samples(x_i)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "\n",
    "        sol_D1_fun = lambda x: batch_jacobian(model, x, create_graph=True)[:,0,:]\n",
    "        sol_D2 = batch_jacobian(sol_D1_fun, x_i, create_graph=True)[:,:,:]\n",
    "        lap = torch.sum(torch.diagonal(sol_D2, dim1=1, dim2=2), dim=1, keepdim=True)\n",
    "        source = source_fun(x_i)\n",
    "        pde_loss = torch.mean((lap - source)**2)\n",
    "\n",
    "        bc_true = sol_fun(x_b)\n",
    "        bc_pred = model(x_b)\n",
    "        bc_loss = torch.mean((bc_pred-bc_true)**2)\n",
    "\n",
    "        loss = alpha * pde_loss + bc_loss\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            sol_D2_test = batch_jacobian(sol_D1_fun, x_test_i, create_graph=True)[:,:,:]\n",
    "            lap_test = torch.sum(torch.diagonal(sol_D2_test, dim1=1, dim2=2), dim=1, keepdim=True)\n",
    "            source_test = source_fun(x_test_i)\n",
    "            pde_loss_test = torch.mean((lap_test - source_test)**2)\n",
    "    \n",
    "            bc_true_test = sol_fun(x_test_b)\n",
    "            bc_pred_test = model(x_test_b)\n",
    "            bc_loss_test = torch.mean((bc_pred_test-bc_true_test)**2)\n",
    "    \n",
    "            l2_test = torch.mean((model(x_test).cpu() - sol)**2)\n",
    "            l2_test_std = torch.std((model(x_test).cpu() - sol)**2)\n",
    "    \n",
    "            pde_losses.append(pde_loss.cpu().detach().numpy())\n",
    "            bc_losses.append(bc_loss.cpu().detach().numpy())\n",
    "            pde_losses_test.append(pde_loss_test.cpu().detach().numpy())\n",
    "            bc_losses_test.append(bc_loss_test.cpu().detach().numpy())\n",
    "            l2_losses_test.append(l2_test.cpu().detach().numpy())\n",
    "            l2_losses_std_test.append(l2_test_std.cpu().detach().numpy())\n",
    "\n",
    "    elapsed = (time.time() - start)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(x_test).cpu().clone().detach().numpy().reshape(X_test_np.shape)\n",
    "    \n",
    "    return output, losses, pde_losses, bc_losses, pde_losses_test, bc_losses_test, l2_losses_test, l2_losses_std_test, elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Define the function to plot ground-truth solution, learnt solutions and their residual difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fig(relu_kan_, hrkan_, kan_, i):\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(25,8), subplot_kw={\"projection\": \"3d\"})\n",
    "    fig.suptitle('Solutions and their residual difference')\n",
    "    \n",
    "    #true solution\n",
    "    surf1 = axs[0,0].plot_surface(X_test_np, Y_test_np, sol.reshape(X_test_np.shape), cmap=cm.coolwarm,linewidth=0, antialiased=False)\n",
    "    axs[0,0].set_zlim(-1.01, 1.01)\n",
    "    axs[0,0].zaxis.set_major_locator(LinearLocator(10))\n",
    "    axs[0,0].zaxis.set_major_formatter('{x:.02f}')\n",
    "    axs[0,0].set(xlabel='x', ylabel='t', zlabel='u(x,t)', title=\"Ground-truth\")\n",
    "    \n",
    "    # RELU_KAN\n",
    "    surf2 = axs[0,1].plot_surface(X_test_np, Y_test_np, relu_kan_[0], cmap=cm.coolwarm,linewidth=0, antialiased=False)\n",
    "    axs[0,1].set_zlim(-1.01, 1.01)\n",
    "    axs[0,1].zaxis.set_major_locator(LinearLocator(10))\n",
    "    axs[0,1].zaxis.set_major_formatter('{x:.02f}')\n",
    "    axs[0,1].set(xlabel='x', ylabel='t', zlabel='u(x,t)', title=\"ReLU-Kan solution\")\n",
    "    \n",
    "    surf3 = axs[1,1].plot_surface(X_test_np, Y_test_np, (sol - relu_kan_[0]), cmap=cm.coolwarm,linewidth=0, antialiased=False)\n",
    "    axs[1,1].set_zlim(-1.01, 1.01)\n",
    "    axs[1,1].zaxis.set_major_locator(LinearLocator(10))\n",
    "    axs[1,1].zaxis.set_major_formatter('{x:.02f}')\n",
    "    axs[1,1].set(xlabel='x', ylabel='t', zlabel='u(x,t)', title=\"ReLU-Kan residual\")\n",
    "    \n",
    "    # HRKAN\n",
    "    surf4 = axs[0,2].plot_surface(X_test_np, Y_test_np, hrkan_[0], cmap=cm.coolwarm,linewidth=0, antialiased=False)\n",
    "    axs[0,2].set_zlim(-1.01, 1.01)\n",
    "    axs[0,2].zaxis.set_major_locator(LinearLocator(10))\n",
    "    axs[0,2].zaxis.set_major_formatter('{x:.02f}')\n",
    "    axs[0,2].set(xlabel='x', ylabel='t', zlabel='u(x,t)', title=\"HRKan solution\")\n",
    "    \n",
    "    surf5 = axs[1,2].plot_surface(X_test_np, Y_test_np, (sol - hrkan_[0]), cmap=cm.coolwarm,linewidth=0, antialiased=False)\n",
    "    axs[1,2].set_zlim(-1.01, 1.01)\n",
    "    axs[1,2].zaxis.set_major_locator(LinearLocator(10))\n",
    "    axs[1,2].zaxis.set_major_formatter('{x:.02f}')\n",
    "    axs[1,2].set(xlabel='x', ylabel='t', zlabel='u(x,t)', title=\"HRKan residual\")\n",
    "    \n",
    "    # KAN\n",
    "    surf6 = axs[0,3].plot_surface(X_test_np, Y_test_np, kan_[0], cmap=cm.coolwarm,linewidth=0, antialiased=False)\n",
    "    axs[0,3].set_zlim(-1.01, 1.01)\n",
    "    axs[0,3].zaxis.set_major_locator(LinearLocator(10))\n",
    "    axs[0,3].zaxis.set_major_formatter('{x:.02f}')\n",
    "    axs[0,3].set(xlabel='x', ylabel='t', zlabel='u(x,t)', title=\"Kan solution\")\n",
    "    \n",
    "    surf7 = axs[1,3].plot_surface(X_test_np, Y_test_np, (sol - kan_[0]), cmap=cm.coolwarm,linewidth=0, antialiased=False)\n",
    "    axs[1,3].set_zlim(-1.01, 1.01)\n",
    "    axs[1,3].zaxis.set_major_locator(LinearLocator(10))\n",
    "    axs[1,3].zaxis.set_major_formatter('{x:.02f}')\n",
    "    axs[1,3].set(xlabel='x', ylabel='t', zlabel='u(x,t)', title=\"Kan residual\")\n",
    "    \n",
    "    cb1 = fig.colorbar(surf1, ax=axs, orientation='vertical')\n",
    "\n",
    "    plt.savefig(f'Poisson_fig_{i}.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Define the function to calculate MSE, MSE std. and training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_kan_loss, relu_kan_loss_test, relu_kan_L2s, relu_kan_L2s_std, relu_kan_time = [], [], [], [], []\n",
    "hrkan_loss, hrkan_loss_test, hrkan_L2s, hrkan_L2s_std, hrkan_time = [], [], [], [], []\n",
    "kan_loss, kan_loss_test, kan_L2s, kan_L2s_std, kan_time = [], [], [], [], []\n",
    "def cal_error(relu_kan_, hrkan_, kan_, i):\n",
    "    relu_kan_loss.append([alpha * x + y for x, y in zip(relu_kan_[2], relu_kan_[3])])\n",
    "    relu_kan_loss_test.append([alpha * x + y for x, y in zip(relu_kan_[4], relu_kan_[5])])\n",
    "    relu_kan_L2s.append(relu_kan_[-3])\n",
    "    relu_kan_L2s_std.append(relu_kan_[-2])\n",
    "    relu_kan_time.append(relu_kan_[-1])\n",
    "    hrkan_loss.append([alpha * x + y for x, y in zip(hrkan_[2], hrkan_[3])])\n",
    "    hrkan_loss_test.append([alpha * x + y for x, y in zip(hrkan_[4], hrkan_[5])])\n",
    "    hrkan_L2s.append(hrkan_[-3])\n",
    "    hrkan_L2s_std.append(hrkan_[-2])\n",
    "    hrkan_time.append(hrkan_[-1])\n",
    "    kan_loss.append([alpha * x + y for x, y in zip(kan_[2], kan_[3])])\n",
    "    kan_loss_test.append([alpha * x + y for x, y in zip(kan_[4], kan_[5])])\n",
    "    kan_L2s.append(kan_[-3])\n",
    "    kan_L2s_std.append(kan_[-2])\n",
    "    kan_time.append(kan_[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "relu_kans = []\n",
    "hrkans = []\n",
    "kans = []\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    relu_kan = ReLUKAN([2,2,1], 5, 3, -1, 1)\n",
    "    relu_kan = relu_kan.cuda()\n",
    "    relu_kan_results = train_model(relu_kan)\n",
    "    del relu_kan\n",
    "    hrkan = HRKAN([2,2,1], 5, 3, -1, 1, 4)\n",
    "    hrkan = hrkan.cuda()\n",
    "    hrkan_results = train_model(hrkan)\n",
    "    del hrkan\n",
    "    kan = KAN(width=[2,2,1], grid=5, k=3, grid_eps=1.0, device='cuda')\n",
    "    kan_results = train_kan(kan)\n",
    "    del hrkan\n",
    "    plot_fig(relu_kan_results, hrkan_results, kan_results, i)\n",
    "    cal_error(relu_kan_results, hrkan_results, kan_results, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Plot the median losses and MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_median=5\n",
    "q1_quantile = 0\n",
    "q2_quantile = -1\n",
    "fig, axs = plt.subplots(3, 3, figsize=(25,18))\n",
    "fig.suptitle('Loss and accuracy (median and max-min-band of 10 runs)')\n",
    "\n",
    "axs[0,0].plot(np.arange(3000),np.sort(np.array(hrkan_loss), axis=0)[k_median,:])\n",
    "axs[0,0].plot(np.arange(3000),np.sort(np.array(relu_kan_loss), axis=0)[k_median,:])\n",
    "axs[0,0].plot(np.arange(3000),np.sort(np.array(kan_loss), axis=0)[k_median,:])\n",
    "axs[0,0].legend(['HRKan', 'ReLU-Kan', 'Kan'])\n",
    "axs[0,0].fill_between(np.arange(3000),np.sort(np.array(hrkan_loss), axis=0)[q1_quantile,:], np.sort(np.array(hrkan_loss), axis=0)[q2_quantile,:], alpha=0.3)\n",
    "axs[0,0].fill_between(np.arange(3000),np.sort(np.array(relu_kan_loss), axis=0)[q1_quantile,:], np.sort(np.array(relu_kan_loss), axis=0)[q2_quantile,:], alpha=0.3)\n",
    "axs[0,0].fill_between(np.arange(3000),np.sort(np.array(kan_loss), axis=0)[q1_quantile,:], np.sort(np.array(kan_loss), axis=0)[q2_quantile,:], alpha=0.3)\n",
    "axs[0,0].set(xlabel='epoch', ylabel='loss', title=\"Training loss\")\n",
    "\n",
    "axs[0,1].plot(np.arange(1000,3000),np.sort(np.array(hrkan_loss), axis=0)[k_median,1000:])\n",
    "axs[0,1].plot(np.arange(1000,3000),np.sort(np.array(relu_kan_loss), axis=0)[k_median,1000:])\n",
    "axs[0,1].plot(np.arange(1000,3000),np.sort(np.array(kan_loss), axis=0)[k_median,1000:])\n",
    "axs[0,1].legend(['HRKan', 'ReLU-Kan', 'Kan'])\n",
    "axs[0,1].fill_between(np.arange(1000,3000),np.sort(np.array(hrkan_loss), axis=0)[q1_quantile,1000:], np.sort(np.array(hrkan_loss), axis=0)[q2_quantile,1000:], alpha=0.3)\n",
    "axs[0,1].fill_between(np.arange(1000,3000),np.sort(np.array(relu_kan_loss), axis=0)[q1_quantile,1000:], np.sort(np.array(relu_kan_loss), axis=0)[q2_quantile,1000:], alpha=0.3)\n",
    "axs[0,1].fill_between(np.arange(1000,3000),np.sort(np.array(kan_loss), axis=0)[q1_quantile,1000:], np.sort(np.array(kan_loss), axis=0)[q2_quantile,1000:], alpha=0.3)\n",
    "axs[0,1].set(xlabel='epoch', ylabel='loss', title=\"Training loss\")\n",
    "\n",
    "axs[0,2].plot(np.arange(2000,3000),np.sort(np.array(hrkan_loss), axis=0)[k_median,2000:])\n",
    "axs[0,2].plot(np.arange(2000,3000),np.sort(np.array(relu_kan_loss), axis=0)[k_median,2000:])\n",
    "axs[0,2].plot(np.arange(2000,3000),np.sort(np.array(kan_loss), axis=0)[k_median,2000:])\n",
    "axs[0,2].legend(['HRKan', 'ReLU-Kan', 'Kan'])\n",
    "axs[0,2].fill_between(np.arange(2000,3000),np.sort(np.array(hrkan_loss), axis=0)[q1_quantile,2000:], np.sort(np.array(hrkan_loss), axis=0)[q2_quantile,2000:], alpha=0.3)\n",
    "axs[0,2].fill_between(np.arange(2000,3000),np.sort(np.array(relu_kan_loss), axis=0)[q1_quantile,2000:], np.sort(np.array(relu_kan_loss), axis=0)[q2_quantile,2000:], alpha=0.3)\n",
    "axs[0,2].fill_between(np.arange(2000,3000),np.sort(np.array(kan_loss), axis=0)[q1_quantile,2000:], np.sort(np.array(kan_loss), axis=0)[q2_quantile,2000:], alpha=0.3)\n",
    "axs[0,2].set(xlabel='epoch', ylabel='loss', title=\"Training loss\")\n",
    "\n",
    "axs[1,0].plot(np.arange(3000),np.sort(np.array(hrkan_loss_test), axis=0)[k_median,:])\n",
    "axs[1,0].plot(np.arange(3000),np.sort(np.array(relu_kan_loss_test), axis=0)[k_median,:])\n",
    "axs[1,0].plot(np.arange(3000),np.sort(np.array(kan_loss_test), axis=0)[k_median,:])\n",
    "axs[1,0].legend(['HRKan', 'ReLU-Kan', 'Kan'])\n",
    "axs[1,0].fill_between(np.arange(3000),np.sort(np.array(hrkan_loss_test), axis=0)[q1_quantile,:], np.sort(np.array(hrkan_loss_test), axis=0)[q2_quantile,:], alpha=0.3)\n",
    "axs[1,0].fill_between(np.arange(3000),np.sort(np.array(relu_kan_loss_test), axis=0)[q1_quantile,:], np.sort(np.array(relu_kan_loss_test), axis=0)[q2_quantile,:], alpha=0.3)\n",
    "axs[1,0].fill_between(np.arange(3000),np.sort(np.array(kan_loss_test), axis=0)[q1_quantile,:], np.sort(np.array(kan_loss_test), axis=0)[q2_quantile,:], alpha=0.3)\n",
    "axs[1,0].set(xlabel='epoch', ylabel='loss', title=\"Test loss\")\n",
    "\n",
    "axs[1,1].plot(np.arange(1000,3000),np.sort(np.array(hrkan_loss_test), axis=0)[k_median,1000:])\n",
    "axs[1,1].plot(np.arange(1000,3000),np.sort(np.array(relu_kan_loss_test), axis=0)[k_median,1000:])\n",
    "axs[1,1].plot(np.arange(1000,3000),np.sort(np.array(kan_loss_test), axis=0)[k_median,1000:])\n",
    "axs[1,1].fill_between(np.arange(1000,3000),np.sort(np.array(hrkan_loss_test), axis=0)[q1_quantile,1000:], np.sort(np.array(hrkan_loss_test), axis=0)[q2_quantile,1000:], alpha=0.3)\n",
    "axs[1,1].fill_between(np.arange(1000,3000),np.sort(np.array(relu_kan_loss_test), axis=0)[q1_quantile,1000:], np.sort(np.array(relu_kan_loss_test), axis=0)[q2_quantile,1000:], alpha=0.3)\n",
    "axs[1,1].fill_between(np.arange(1000,3000),np.sort(np.array(kan_loss_test), axis=0)[q1_quantile,1000:], np.sort(np.array(kan_loss_test), axis=0)[q2_quantile,1000:], alpha=0.3)\n",
    "axs[1,1].legend(['HRKan', 'ReLU-Kan', 'Kan'])\n",
    "axs[1,1].set(xlabel='epoch', ylabel='loss', title=\"Test loss\")\n",
    "\n",
    "axs[1,2].plot(np.arange(2000,3000),np.sort(np.array(hrkan_loss_test), axis=0)[k_median,2000:])\n",
    "axs[1,2].plot(np.arange(2000,3000),np.sort(np.array(relu_kan_loss_test), axis=0)[k_median,2000:])\n",
    "axs[1,2].plot(np.arange(2000,3000),np.sort(np.array(kan_loss_test), axis=0)[k_median,2000:])\n",
    "axs[1,2].fill_between(np.arange(2000,3000),np.sort(np.array(hrkan_loss_test), axis=0)[q1_quantile,2000:], np.sort(np.array(hrkan_loss_test), axis=0)[q2_quantile,2000:], alpha=0.3)\n",
    "axs[1,2].fill_between(np.arange(2000,3000),np.sort(np.array(relu_kan_loss_test), axis=0)[q1_quantile,2000:], np.sort(np.array(relu_kan_loss_test), axis=0)[q2_quantile,2000:], alpha=0.3)\n",
    "axs[1,2].fill_between(np.arange(2000,3000),np.sort(np.array(kan_loss_test), axis=0)[q1_quantile,2000:], np.sort(np.array(kan_loss_test), axis=0)[q2_quantile,2000:], alpha=0.3)\n",
    "axs[1,2].legend(['HRKan', 'ReLU-Kan', 'Kan'])\n",
    "axs[1,2].set(xlabel='epoch', ylabel='loss', title=\"Test loss\")\n",
    "\n",
    "axs[2,0].plot(np.arange(3000),np.sort(np.array(hrkan_L2s), axis=0)[k_median,:])\n",
    "axs[2,0].plot(np.arange(3000),np.sort(np.array(relu_kan_L2s), axis=0)[k_median,:])\n",
    "axs[2,0].plot(np.arange(3000),np.sort(np.array(kan_L2s), axis=0)[k_median,:])\n",
    "axs[2,0].fill_between(np.arange(3000),np.sort(np.array(hrkan_L2s), axis=0)[q1_quantile,:], np.sort(np.array(hrkan_L2s), axis=0)[q2_quantile,:], alpha=0.3)\n",
    "axs[2,0].fill_between(np.arange(3000),np.sort(np.array(relu_kan_L2s), axis=0)[q1_quantile,:], np.sort(np.array(relu_kan_L2s), axis=0)[q2_quantile,:], alpha=0.3)\n",
    "axs[2,0].fill_between(np.arange(3000),np.sort(np.array(kan_L2s), axis=0)[q1_quantile,:], np.sort(np.array(kan_L2s), axis=0)[q2_quantile,:], alpha=0.3)\n",
    "axs[2,0].legend(['HRKan', 'ReLU-Kan', 'Kan'])\n",
    "axs[2,0].set(xlabel='epoch', ylabel='MSE', title=\"Test MSE\")\n",
    "\n",
    "axs[2,1].plot(np.arange(1000,3000),np.sort(np.array(hrkan_L2s), axis=0)[k_median,1000:])\n",
    "axs[2,1].plot(np.arange(1000,3000),np.sort(np.array(relu_kan_L2s), axis=0)[k_median,1000:])\n",
    "axs[2,1].plot(np.arange(1000,3000),np.sort(np.array(kan_L2s), axis=0)[k_median,1000:])\n",
    "axs[2,1].legend(['HRKan', 'ReLU-Kan', 'Kan'])\n",
    "axs[2,1].fill_between(np.arange(1000,3000),np.sort(np.array(hrkan_L2s), axis=0)[q1_quantile,1000:], np.sort(np.array(hrkan_L2s), axis=0)[q2_quantile,1000:], alpha=0.3)\n",
    "axs[2,1].fill_between(np.arange(1000,3000),np.sort(np.array(relu_kan_L2s), axis=0)[q1_quantile,1000:], np.sort(np.array(relu_kan_L2s), axis=0)[q2_quantile,1000:], alpha=0.3)\n",
    "axs[2,1].fill_between(np.arange(1000,3000),np.sort(np.array(kan_L2s), axis=0)[q1_quantile,1000:], np.sort(np.array(kan_L2s), axis=0)[q2_quantile,1000:], alpha=0.3)\n",
    "axs[2,1].set(xlabel='epoch', ylabel='MSE', title=\"Test MSE\")\n",
    "\n",
    "axs[2,2].plot(np.arange(2000,3000),np.sort(np.array(hrkan_L2s), axis=0)[k_median,2000:])\n",
    "axs[2,2].plot(np.arange(2000,3000),np.sort(np.array(relu_kan_L2s), axis=0)[k_median,2000:])\n",
    "axs[2,2].plot(np.arange(2000,3000),np.sort(np.array(kan_L2s), axis=0)[k_median,2000:])\n",
    "axs[2,2].legend(['HRKan', 'ReLU-Kan', 'Kan'])\n",
    "axs[2,2].fill_between(np.arange(2000,3000),np.sort(np.array(hrkan_L2s), axis=0)[q1_quantile,2000:], np.sort(np.array(hrkan_L2s), axis=0)[q2_quantile,2000:], alpha=0.3)\n",
    "axs[2,2].fill_between(np.arange(2000,3000),np.sort(np.array(relu_kan_L2s), axis=0)[q1_quantile,2000:], np.sort(np.array(relu_kan_L2s), axis=0)[q2_quantile,2000:], alpha=0.3)\n",
    "axs[2,2].fill_between(np.arange(2000,3000),np.sort(np.array(kan_L2s), axis=0)[q1_quantile,2000:], np.sort(np.array(kan_L2s), axis=0)[q2_quantile,2000:], alpha=0.3)\n",
    "axs[2,2].set(xlabel='epoch', ylabel='MSE', title=\"Test MSE\")\n",
    "\n",
    "plt.savefig(f'Poisson_loss_band.png', dpi=400)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Calculate mean MSE, mean MSE std. and mean training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"{0:.5g}\".format(np.array(relu_kan_L2s)[:,-1].mean()), \"{0:.5g}\".format(np.array(relu_kan_L2s_std)[:,-1].mean()), \"{0:.5g}\".format(np.array(relu_kan_time)[-1].mean()))\n",
    "print( \"{0:.5g}\".format(np.array(hrkan_L2s)[:,-1].mean()), \"{0:.5g}\".format(np.array(hrkan_L2s_std)[:,-1].mean()), \"{0:.5g}\".format(np.array(hrkan_time)[-1].mean()))\n",
    "print( \"{0:.5g}\".format(np.array(kan_L2s)[:,-1].mean()), \"{0:.5g}\".format(np.array(kan_L2s_std)[:,-1].mean()), \"{0:.5g}\".format(np.array(kan_time)[-1].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ANN",
   "language": "python",
   "name": "ann"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
